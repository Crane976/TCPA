# preprocess/step3_build_global_scaler.py (FINAL 3-TIER COMPATIBLE VERSION)
import pandas as pd
import numpy as np
import os
import joblib
import sys
from sklearn.preprocessing import MinMaxScaler

# ==========================================================
# --- è·¯å¾„ä¿®æ­£ä¸æ¨¡å—å¯¼å…¥ ---
# ==========================================================
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.append(project_root)

# âœ…âœ…âœ… æ ¸å¿ƒä¿®æ”¹: å¯¼å…¥æ–°çš„ã€æœ€å¹¿é˜”çš„ç‰¹å¾é›† âœ…âœ…âœ…
from config import DEFENDER_SET

# ==========================================================
# --- 1. é…ç½®åŒº ---
# ==========================================================
# è¾“å…¥: åªä½¿ç”¨ä¸¥æ ¼åˆ†ç¦»çš„è®­ç»ƒé›†æ¥è®­ç»ƒScaler
INPUT_PATH = os.path.join(project_root, 'data', 'splits', 'training_set.csv')

# è¾“å‡º: æˆ‘ä»¬çš„å…¨å±€â€œåº¦é‡è¡¡â€
SCALER_PATH = os.path.join(project_root, 'models', 'global_scaler.pkl')


# ==========================================================
# --- 2. ä¸»å‡½æ•° ---
# ==========================================================
def main():
    print("==========================================================")
    print("ğŸš€ STEP 3 (Final): æ„å»ºå…¨å±€Scaler (åŸºäºæœ€å¹¿é˜”çš„DEFENDER_SET)")
    print("==========================================================")

    try:
        print(f"æ­£åœ¨ä»ä¸¥æ ¼åˆ†ç¦»çš„è®­ç»ƒé›†åŠ è½½æ•°æ®: {INPUT_PATH}...")
        df_train = pd.read_csv(INPUT_PATH, low_memory=False)
    except FileNotFoundError as e:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°è®­ç»ƒé›†æ–‡ä»¶ - {e}")
        return

    # --- 1. æ•°æ®éªŒè¯ä¸æ¸…ç† ---
    # æˆ‘ä»¬åªå…³å¿ƒç‰¹å¾åˆ—ï¼Œæ ‡ç­¾åˆ—(label)ä¸å‚ä¸Scalerçš„è®­ç»ƒ
    print(f"Scalerå°†åŸºäº {len(DEFENDER_SET)} ä¸ªé˜²å¾¡è€…è§†é‡å†…çš„ç‰¹å¾è¿›è¡Œè®­ç»ƒã€‚")

    # âœ…âœ…âœ… æ ¸å¿ƒä¿®æ”¹: ä½¿ç”¨DEFENDER_SETæ¥é€‰æ‹©ç‰¹å¾ âœ…âœ…âœ…
    df_features = df_train[DEFENDER_SET].copy()

    # æ¸…ç†æ— ç©·å¤§å’ŒNaNå€¼
    df_features.replace([np.inf, -np.inf], np.nan, inplace=True)
    # æ£€æŸ¥æ˜¯å¦æœ‰æ•´åˆ—éƒ½æ˜¯NaNçš„æƒ…å†µï¼Œè¿™å¯èƒ½åœ¨æ•°æ®å­é›†ä¸­å‘ç”Ÿ
    df_features.dropna(axis=1, how='all', inplace=True)
    df_features.dropna(axis=0, how='any', inplace=True)  # ä¸¢å¼ƒä»»ä½•å«æœ‰NaNçš„è¡Œ

    print(f"æ•°æ®æ¸…ç†åï¼Œç”¨äºè®­ç»ƒScalerçš„æ ·æœ¬æ€»æ•°: {len(df_features)}")
    if len(df_features) == 0:
        print("é”™è¯¯ï¼šæ•°æ®æ¸…ç†åæ²¡æœ‰å‰©ä½™æ ·æœ¬ï¼Œè¯·æ£€æŸ¥æ‚¨çš„ training_set.csv å’Œ DEFENDER_SET ä¸­çš„ç‰¹å¾ã€‚")
        return

    # --- 2. è®­ç»ƒå…¨å±€Scaler ---
    print("\næ­£åœ¨è®­ç»ƒå…¨å±€Scaler...")
    scaler = MinMaxScaler()

    # æ ¸å¿ƒæ“ä½œ: åœ¨è®­ç»ƒé›†çš„DEFENDER_SETä¸Š .fit()
    scaler.fit(df_features)

    # --- 3. ä¿å­˜ç»“æœ ---
    joblib.dump(scaler, SCALER_PATH)
    print(f"âœ… å…¨å±€Scalerå·²ä¿å­˜åˆ°: {SCALER_PATH}")
    print("\næ­¤è„šæœ¬ä»»åŠ¡å®Œæˆã€‚åç»­æ‰€æœ‰æ­¥éª¤éƒ½å°†åŠ è½½æ­¤Scaleræ¥è½¬æ¢æ•°æ®ã€‚")


if __name__ == "__main__":
    main()