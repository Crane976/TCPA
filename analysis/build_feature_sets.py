# analysis/build_feature_sets.py (Fixed Version 3 - Corrected Cleaning Order)
import pandas as pd
import numpy as np
import os
from sklearn.preprocessing import MinMaxScaler

# ==========================================================
# --- 1. é…ç½®åŒº ---
# ==========================================================
BENIGN_IN = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'data', 'filtered',
                         'benign_traffic.csv')
BOT_IN = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'data', 'filtered',
                      'bot_traffic_target.csv')

# --- æ ¸å¿ƒç­›é€‰å‚æ•° ---
LOW_VARIANCE_THRESHOLD = 0.001
HIGH_MISSING_RATE_THRESHOLD = 0.1
TIME_ANCHOR_FEATURES = [
    'Flow Duration', 'Flow IAT Mean', 'Fwd IAT Mean', 'Bwd IAT Mean'
]
CORRELATION_THRESHOLD = 0.1
COLLINEARITY_THRESHOLD = 0.95
ALLOWED_PREFIXES = ('Flow', 'Fwd IAT', 'Bwd IAT', 'Idle', 'Active')


# ==========================================================
# --- 2. ä¸»åˆ†æå‡½æ•° ---
# ==========================================================
def main():
    print("==========================================================")
    print("ğŸš€ å¼€å§‹æ„å»ºä¸‰å±‚ç‰¹å¾ä½“ç³» (å€™é€‰é›† -> ç»Ÿä¸€é›† -> æŒ‡çº¹é›†)...")
    print("==========================================================")

    # --- åŠ è½½å¹¶åˆå¹¶æ•°æ® ---
    print("æ­£åœ¨åŠ è½½å®Œæ•´çš„filteredæ•°æ®é›†...")
    df_benign = pd.read_csv(BENIGN_IN, low_memory=False)
    df_bot = pd.read_csv(BOT_IN, low_memory=False)
    df_full = pd.concat([df_benign, df_bot], ignore_index=True)
    df_full.columns = df_full.columns.str.strip()
    df_full.replace([np.inf, -np.inf], np.nan, inplace=True)
    print(f"æ•°æ®é›†åŠ è½½å®Œæ¯•ï¼Œå…± {len(df_full)} æ¡æ ·æœ¬ï¼Œ{len(df_full.columns)} ä¸ªåŸå§‹ç‰¹å¾ã€‚")

    # --- æ­¥éª¤ä¸€: æ„å»ºâ€œå€™é€‰ç‰¹å¾é›†â€ (æ•°æ®è´¨é‡ç­›é€‰) ---
    print("\n--- æ­¥éª¤ä¸€: æ„å»º'å€™é€‰ç‰¹å¾é›†' (CANDIDATE_FEATURE_SET) ---")
    numeric_features = df_full.select_dtypes(include=np.number).columns.tolist()
    missing_rates = df_full[numeric_features].isnull().sum() / len(df_full)
    high_missing_features = missing_rates[missing_rates > HIGH_MISSING_RATE_THRESHOLD].index.tolist()
    candidate_features_step1 = [f for f in numeric_features if f not in high_missing_features]

    # âœ… æ ¸å¿ƒä¿®æ­£: åªä¸ºæ–¹å·®è®¡ç®—åˆ›å»ºä¸€ä¸ªä¸´æ—¶å¡«å……çš„DataFrame
    df_for_variance = df_full[candidate_features_step1].copy()
    df_for_variance.fillna(df_for_variance.median(), inplace=True)

    variances = df_for_variance.var()
    low_variance_features = variances[variances < LOW_VARIANCE_THRESHOLD].index.tolist()
    candidate_feature_set = [f for f in candidate_features_step1 if f not in low_variance_features]
    print(f"âœ… 'å€™é€‰ç‰¹å¾é›†' æ„å»ºå®Œæˆï¼Œå…± {len(candidate_feature_set)} ä¸ªç‰¹å¾ã€‚")

    # ==========================================================
    # --- æ­¥éª¤äºŒ: æ„å»ºâ€œç»Ÿä¸€ç‰¹å¾é›†â€ (ç›¸å…³æ€§ä¸å…±çº¿æ€§ç­›é€‰) ---
    # ==========================================================
    print("\n--- æ­¥éª¤äºŒ: æ„å»º'ç»Ÿä¸€ç‰¹å¾é›†' (UNIFIED_FEATURE_SET) ---")

    # âœ… æ ¸å¿ƒä¿®æ­£: ä½¿ç”¨åŸå§‹çš„ã€å¸¦æœ‰NaNçš„å€™é€‰é›†æ•°æ®è¿›è¡Œä¸‹ä¸€æ­¥
    df_for_corr_raw = df_full[candidate_feature_set].copy()

    print("  - æ­£åœ¨å¯¹æ•°æ®è¿›è¡Œä¸´æ—¶å½’ä¸€åŒ–ä»¥è¿›è¡Œç›¸å…³æ€§åˆ†æ...")
    temp_scaler = MinMaxScaler()
    df_for_corr_scaled = pd.DataFrame(temp_scaler.fit_transform(df_for_corr_raw), columns=candidate_feature_set)

    # âœ… æ ¸å¿ƒä¿®æ­£: åœ¨è®¡ç®—ç›¸å…³æ€§æ—¶ï¼Œè®©Pandasè‡ªåŠ¨å¤„ç†æˆå¯¹çš„ç¼ºå¤±å€¼
    # Pandasçš„ .corr() é»˜è®¤ä¼šä½¿ç”¨ 'pairwise' æ–¹æ³•ï¼Œåªè®¡ç®—æ¯å¯¹ç‰¹å¾å…±æœ‰çš„éç¼ºå¤±å€¼
    corr_matrix = df_for_corr_scaled.corr(method='pearson')

    # æ£€æŸ¥é”šç‚¹æ˜¯å¦å­˜åœ¨äºcorr_matrixä¸­
    valid_anchors = [anchor for anchor in TIME_ANCHOR_FEATURES if anchor in corr_matrix.columns]
    if not valid_anchors:
        print("é”™è¯¯: æ²¡æœ‰ä»»ä½•é”šç‚¹ç‰¹å¾å­˜åœ¨äºæœ€ç»ˆçš„å€™é€‰é›†ä¸­ï¼Œæ— æ³•è®¡ç®—ç›¸å…³æ€§ã€‚");
        return

    anchor_correlations = corr_matrix.loc[valid_anchors]
    avg_corr = anchor_correlations.abs().mean(axis=0)  # axis=0, mean across rows for each column
    highly_correlated_features = avg_corr[avg_corr > CORRELATION_THRESHOLD].index.tolist()
    print(f"  - æ‰¾åˆ° {len(highly_correlated_features)} ä¸ªä¸æ—¶é—´é”šç‚¹é«˜åº¦ç›¸å…³çš„ç‰¹å¾ã€‚")

    corr_matrix_subset = corr_matrix.loc[highly_correlated_features, highly_correlated_features]
    to_drop = set()
    for i in range(len(corr_matrix_subset.columns)):
        for j in range(i):
            if abs(corr_matrix_subset.iloc[i, j]) > COLLINEARITY_THRESHOLD:
                colname_i = corr_matrix_subset.columns[i]
                colname_j = corr_matrix_subset.columns[j]
                if colname_i > colname_j:
                    to_drop.add(colname_i)
                else:
                    to_drop.add(colname_j)

    unified_feature_set = sorted([f for f in highly_correlated_features if f not in to_drop])
    to_drop_list = sorted(list(to_drop))
    print(f"  - æ’é™¤ {len(to_drop_list)} ä¸ªé«˜åº¦å…±çº¿æ€§ç‰¹å¾: {to_drop_list}")
    print(f"\nâœ… 'ç»Ÿä¸€ç‰¹å¾é›†' æ„å»ºå®Œæˆï¼Œå…± {len(unified_feature_set)} ä¸ªç‰¹å¾ã€‚")

    # --- æ­¥éª¤ä¸‰ & å›› ... (åç»­ä»£ç ä¸å˜) ...
    print("\n--- æ­¥éª¤ä¸‰: æ„å»º'æ—¶é—´æŒ‡çº¹å…¨æ™¯' (TIME_FINGERPRINT_SET) ---")
    time_fingerprint_set = []
    excluded_by_prefix = []
    for feature in unified_feature_set:
        if feature.startswith(ALLOWED_PREFIXES):
            time_fingerprint_set.append(feature)
        else:
            excluded_by_prefix.append(feature)
    for anchor in valid_anchors:
        if anchor in unified_feature_set and anchor not in time_fingerprint_set:
            time_fingerprint_set.append(anchor)
    time_fingerprint_set = sorted(list(set(time_fingerprint_set)))
    print(f"  - ä»'ç»Ÿä¸€é›†'ä¸­æ ¹æ®å‰ç¼€æ’é™¤äº† {len(excluded_by_prefix)} ä¸ªç‰¹å¾: {excluded_by_prefix}")
    print(f"\nâœ… 'æ—¶é—´æŒ‡ç´‹å…¨æ™¯' æ„å»ºå®Œæˆï¼Œå…± {len(time_fingerprint_set)} ä¸ªç‰¹å¾ã€‚")
    print("\n==========================================================")
    print("               >>> æœ€ç»ˆç‰¹å¾é›†å®šä¹‰ <<<")
    print("==========================================================")
    print("\n# --- è¯·å°†æ­¤éƒ¨åˆ†å¤åˆ¶å¹¶æ›´æ–°åˆ°æ‚¨çš„ config.py æ–‡ä»¶ä¸­ --- #\n")
    print("# æœ€ç»ˆçš„ã€ç§‘å­¦æ„å»ºçš„ç»Ÿä¸€ç‰¹å¾é›†")
    print("UNIFIED_FEATURE_SET = [")
    if unified_feature_set:
        for i in range(0, len(unified_feature_set), 4):
            print(f"    {str(unified_feature_set[i:i + 4]).strip('[]')},")
    print("]\n")
    print("# æœ€ç»ˆçš„ã€å¯åœ¨é—®é¢˜ç©ºé—´æ“ä½œçš„æ—¶é—´æŒ‡çº¹å…¨æ™¯")
    print("TIME_FINGERPRINT_SET = [")
    if time_fingerprint_set:
        for i in range(0, len(time_fingerprint_set), 4):
            print(f"    {str(time_fingerprint_set[i:i + 4]).strip('[]')},")
    print("]\n")
    print("# --- config.py æ›´æ–°å†…å®¹ç»“æŸ --- #")
    print("==========================================================")


if __name__ == "__main__":
    main()