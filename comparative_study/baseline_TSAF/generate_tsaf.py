# comparative_study/baseline_TSAF/generate_tsaf.py
# Baseline Implementation: TSAF (Time Series Adversarial Framework)
# Reference: Lu et al., Computers & Security 2025
# Logic: Iterative FGSM (I-FGSM) as described in TSAF Algorithm 1

import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import os
import sys
import joblib

# --- è·¯å¾„é€‚é… ---
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if project_root not in sys.path: sys.path.append(project_root)

import config
from config import DEFENDER_SET, set_seed
from models.cnn_architecture import CNN_Classifier

# ==========================================================
# --- é…ç½®åŒº (Match TSAF Algo 1 Inputs) ---
# ==========================================================
# TSAF Algorithm 1 Parameters:
# - n: number of perturbations (Implemented via Mask)
# - epsilon (learning rate/step size): 0.01 (ALPHA)
# - T (iterations): 20
# - dom_range: [0, 1] (Ensured by Scaler & Clip)

MAX_PERTURBATION = 0.1  # å¯¹åº” L-inf norm constraint
STEP_SIZE = 0.01  # å¯¹åº” Algorithm 1 ä¸­çš„ learning rate epsilon
ITERATIONS = 20  # å¯¹åº” Algorithm 1 ä¸­çš„ T

# TSAF å¼ºè°ƒåªä¿®æ”¹æ—¶é—´ç‰¹å¾
TIME_FEATURES_KEYWORDS = ['Duration', 'IAT', 'Active', 'Idle']

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def get_time_feature_mask(feature_names):
    """
    [TSAF Function 20] get_mask
    ç”ŸæˆæŽ©ç ï¼Œåªå…è®¸æ—¶é—´ç‰¹å¾è¢«ä¿®æ”¹
    """
    mask = []
    print("\n[TSAF Constraint] Locking non-time features (Spatial & Header)...")
    for feat in feature_names:
        # ä¸¥æ ¼ç­›é€‰ï¼šå¿…é¡»åŒ…å«æ—¶é—´å…³é”®å­—ï¼Œä¸”ä¸èƒ½æ˜¯é€ŸçŽ‡ï¼ˆé€ŸçŽ‡æ˜¯è®¡ç®—ç»“æžœï¼‰
        is_time = any(k in feat for k in TIME_FEATURES_KEYWORDS)
        if is_time and 'Bytes/s' not in feat and 'Packets/s' not in feat:
            mask.append(1.0)
        else:
            mask.append(0.0)

    mask_tensor = torch.tensor(mask, dtype=torch.float32).to(device)
    print(f"   -> Mask generated. {int(mask_tensor.sum().item())} time features represent the attack surface.")
    return mask_tensor


def iterative_fgsm_attack(model, data_x, target_y, mask, eps, alpha, T):
    """
    [TSAF Algorithm 1] TSAF attack for flow-based time series IDS
    æœ¬è´¨æ˜¯ Iterative-FGSM (I-FGSM)
    """
    # 4: Initialize delta randomly (Small random start to escape local minima)
    delta = torch.zeros_like(data_x).uniform_(-0.01, 0.01).to(device) * mask
    delta.requires_grad = True

    # åŠ¨æ€é€‰æ‹© Loss (é€‚é…äºŒåˆ†ç±»/å¤šåˆ†ç±»)
    with torch.no_grad():
        test_out = model(data_x[:1])
    use_bce = (test_out.shape[1] == 1)

    if use_bce:
        loss_fn = nn.BCEWithLogitsLoss()
    else:
        loss_fn = nn.CrossEntropyLoss()

    # 7: for step in [1, T] do
    for t in range(T):
        # 9: apply_mask_and_adv (Generate perturbed data)
        # x_adv = x + delta
        perturbed_data = data_x + delta
        perturbed_data = torch.clamp(perturbed_data, 0, 1)  # Ensure dom_range

        # 11: compute predictions
        outputs = model(perturbed_data)

        # 12: calculate loss (Targeted: Minimize loss to 'Bot' class)
        if use_bce:
            loss = loss_fn(outputs, target_y.float().view(-1, 1))
        else:
            loss = loss_fn(outputs, target_y)

        # 14: Compute gradients of loss w.r.t. delta
        model.zero_grad()
        loss.backward()
        grad = delta.grad.data

        # Apply Mask to Gradients (TSAF constraint: only time features update)
        grad = grad * mask

        # 15: Update delta using optimizer (Here we use Sign SGD -> FGSM logic)
        # Targeted Attack: Gradient Descent (Move towards target class 1)
        delta.data = delta.data - alpha * grad.sign()

        # Projection (Clip delta to stay within epsilon ball)
        delta.data = torch.clamp(delta.data, -eps, eps)

        # Re-apply mask to delta to be safe
        delta.data = delta.data * mask

        # Reset gradient for next step
        delta.grad.zero_()

    # 17: Apply mask and delta to generate perturbed feature data
    final_adv_x = data_x + delta.detach()
    final_adv_x = torch.clamp(final_adv_x, 0, 1)

    # 18: Return UAP (Here we return the perturbed samples directly)
    return final_adv_x


def main():
    set_seed(2025)
    print("=" * 60)
    print(f"ðŸš€ [Baseline Reproduction] TSAF: Iterative FGSM Framework")
    print(f"   Dataset: {config.CURRENT_DATASET}")
    print("=" * 60)

    # 1. åŠ¨æ€è·¯å¾„ & æ•°é‡
    if config.CURRENT_DATASET == 'CIC-IDS2017':
        NUM_TO_GENERATE = 39300
    else:
        NUM_TO_GENERATE = 100000

    OUTPUT_PATH = os.path.join(project_root, 'data', 'generated', f'baseline_TSAF_{config.CURRENT_DATASET}.csv')

    # 2. åŠ è½½æ•°æ® (Benign è½½ä½“)
    print(f"Loading Benign samples (Source)... Target: {NUM_TO_GENERATE}")
    train_path = os.path.join(config.SPLITS_DIR, 'training_set.csv')

    if not os.path.exists(train_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°è®­ç»ƒé›†æ–‡ä»¶: {train_path}")
        return

    df_train = pd.read_csv(train_path)
    df_benign = df_train[df_train['label'] == 0].sample(n=NUM_TO_GENERATE, replace=True, random_state=2025)

    print(f"Loading Scaler from {config.SCALER_PATH}...")
    scaler = joblib.load(config.SCALER_PATH)

    X_benign = scaler.transform(df_benign[DEFENDER_SET])

    # è½¬ Tensor
    X_benign_tensor = torch.tensor(X_benign, dtype=torch.float32).to(device)
    # ç›®æ ‡æ ‡ç­¾: Bot (1)
    target_labels = torch.ones(NUM_TO_GENERATE, dtype=torch.long).to(device)

    # 3. åŠ è½½ç™½ç›’æ›¿èº«æ¨¡åž‹ (1D-CNN)
    print("Loading Surrogate White-box Model (1D-CNN)...")
    cnn_path = os.path.join(config.MODEL_SAVE_DIR, 'cnn_hunter.pt')

    surrogate_model = CNN_Classifier(feature_dim=len(DEFENDER_SET)).to(device)
    # å¿½ç•¥ pickle è­¦å‘Š
    try:
        surrogate_model.load_state_dict(torch.load(cnn_path, map_location=device))
    except TypeError:
        # Fallback if weights_only arg causes issue on old torch versions
        surrogate_model.load_state_dict(torch.load(cnn_path, map_location=device))

    surrogate_model.eval()

    # 4. ç”Ÿæˆ (Iterative FGSM)
    print(f"Starting TSAF Generation (Iterative FGSM, T={ITERATIONS}, Step={STEP_SIZE})...")

    feature_mask = get_time_feature_mask(DEFENDER_SET)

    BATCH_SIZE = 512
    adv_samples_list = []

    import math
    num_batches = math.ceil(NUM_TO_GENERATE / BATCH_SIZE)

    for i in range(num_batches):
        start_idx = i * BATCH_SIZE
        end_idx = min((i + 1) * BATCH_SIZE, NUM_TO_GENERATE)

        batch_x = X_benign_tensor[start_idx:end_idx]
        batch_y = target_labels[start_idx:end_idx]

        # è°ƒç”¨æ”¹ååŽçš„å‡½æ•°
        adv_batch = iterative_fgsm_attack(
            surrogate_model, batch_x, batch_y, feature_mask,
            eps=MAX_PERTURBATION, alpha=STEP_SIZE, T=ITERATIONS
        )

        adv_samples_list.append(adv_batch.cpu().numpy())

        if i % 20 == 0:
            print(f"   -> Batch {i}/{num_batches} done.")

    X_adv_np = np.concatenate(adv_samples_list, axis=0)

    # 5. ä¿å­˜ä¸ŽåŽå¤„ç†
    print("Inverse scaling...")
    X_adv_original = scaler.inverse_transform(X_adv_np)

    df_adv = pd.DataFrame(X_adv_original, columns=DEFENDER_SET)
    df_adv['Label'] = 1

    # ==========================================================
    # ðŸ”¥ [å…¬å¹³æ€§ä¿®æ­£] Post-processing for Fair Comparison
    # å¼ºåˆ¶ä¿®æ­£ç©ºé—´ç‰¹å¾çš„æµ®ç‚¹è¯¯å·®ï¼Œé¿å… Straw Man æ”»å‡»
    # ==========================================================
    print("Applying Integer Rounding to Spatial Features (Fairness Correction)...")

    integer_cols = [
        'Total Fwd Packets', 'Total Backward Packets',
        'Total Length of Fwd Packets', 'Total Length of Bwd Packets',
        'Fwd Header Length', 'Bwd Header Length',
        'Subflow Fwd Packets', 'Subflow Fwd Bytes',
        'Subflow Bwd Packets', 'Subflow Bwd Bytes',
        'Init_Win_bytes_forward', 'Init_Win_bytes_backward',
        'act_data_pkt_fwd', 'min_seg_size_forward',
        'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',
        'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio'
    ]

    count_fixed = 0
    for col in integer_cols:
        if col in df_adv.columns:
            df_adv[col] = df_adv[col].clip(lower=0)
            df_adv[col] = df_adv[col].round().astype(int)
            count_fixed += 1

    print(f"   -> Fixed {count_fixed} spatial feature columns to Integers.")

    df_adv.to_csv(OUTPUT_PATH, index=False)
    print(f"âœ… TSAF Baseline Generated: {OUTPUT_PATH}")


if __name__ == "__main__":
    main()