# generate/STEP3_generate_camouflage_bot.py (FINAL 3-TIER ASYMMETRIC STRATEGY)
import pandas as pd
import numpy as np
import os
import sys
import joblib
import torch
from tqdm import tqdm

# ==========================================================
# --- è·¯å¾„ä¿®æ­£ä¸æ¨¡å—å¯¼å…¥ ---
# ==========================================================
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.append(project_root)

from models.style_transfer_cae import ConditionalAutoencoder
from models.bot_pattern_lstm import BotPatternLSTM
# âœ…âœ…âœ… 1. å¯¼å…¥æœ€ç»ˆçš„ä¸‰å±‚ç‰¹å¾ä½“ç³» âœ…âœ…âœ…
from config import DEFENDER_SET, ATTACKER_KNOWLEDGE_SET, ATTACKER_ACTION_SET

# ==========================================================
# --- 1. é…ç½®åŒº ---
# ==========================================================
# --- è¾“å…¥ ---
TRAIN_SET_PATH = os.path.join(project_root, 'data', 'splits', 'training_set.csv')
SCALER_PATH = os.path.join(project_root, 'models', 'global_scaler.pkl')
CAE_MODEL_PATH = os.path.join(project_root, 'models', 'style_transfer_cae.pt')
LSTM_MODEL_PATH = os.path.join(project_root, 'models', 'bot_pattern_lstm_final.pt')  # ç¡®ä¿æŒ‡å‘æœ€ç»ˆè®­ç»ƒçš„æ¨¡å‹

# --- è¾“å‡º ---
GENERATED_DIR = os.path.join(project_root, 'data', 'generated')
os.makedirs(GENERATED_DIR, exist_ok=True)
OUTPUT_CAMOUFLAGE_PATH = os.path.join(GENERATED_DIR, 'final_camouflage_bot.csv')

# --- æ¨¡å‹å‚æ•° (ä¸ STEP2 ä¿æŒä¸€è‡´) ---
CAE_FEATURE_DIM = len(ATTACKER_KNOWLEDGE_SET)
LATENT_DIM_CAE = 5
NUM_CLASSES_CAE = 2
INPUT_DIM_LSTM = LATENT_DIM_CAE
OUTPUT_DIM_LSTM = len(ATTACKER_ACTION_SET)
HIDDEN_DIM_LSTM = 64
COND_DIM_LSTM = NUM_CLASSES_CAE

# --- ç”Ÿæˆå‚æ•° ---
NUM_TO_GENERATE = 40000
WINDOW_SIZE = 3
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
PERTURBATION_STRENGTH_ALPHA = 1.0


# ==========================================================
# --- 2. è¾…åŠ©å‡½æ•° ---
# ==========================================================
def create_latent_sequences_for_generation(data, window_size):
    sequences = []
    if len(data) >= window_size:
        for i in range(len(data) - window_size + 1):
            sequences.append(data[i:i + window_size])
    return np.array(sequences)


# ==========================================================
# --- 3. ä¸»ç”Ÿæˆå‡½æ•° ---
# ==========================================================
def main():
    print("=" * 60);
    print("ğŸš€ æ‰°åŠ¨å­¦ä¹ æ¡†æ¶ (æœ€ç»ˆç‰ˆ - ä¸‰å±‚éå¯¹ç§°ç­–ç•¥) - STEP 3: ç”Ÿæˆæµé‡...");
    print("=" * 60)
    print(f"   >>> å½“å‰æ‰°åŠ¨æ”¾å¤§ç³»æ•° (Alpha): {PERTURBATION_STRENGTH_ALPHA} <<<")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # --- åŠ è½½èµ„äº§ ---
    try:
        df_train_full = pd.read_csv(TRAIN_SET_PATH)
        scaler = joblib.load(SCALER_PATH)
        # âœ… 2. åˆå§‹åŒ–æ¨¡å‹æ—¶ä½¿ç”¨æ­£ç¡®çš„ç»´åº¦
        cae_model = ConditionalAutoencoder(CAE_FEATURE_DIM, LATENT_DIM_CAE, NUM_CLASSES_CAE).to(device)
        cae_model.load_state_dict(torch.load(CAE_MODEL_PATH, map_location=device, weights_only=True))
        cae_model.eval()
        lstm_model = BotPatternLSTM(INPUT_DIM_LSTM, HIDDEN_DIM_LSTM, OUTPUT_DIM_LSTM, COND_DIM_LSTM).to(device)
        lstm_model.load_state_dict(torch.load(LSTM_MODEL_PATH, map_location=device, weights_only=True))
        lstm_model.eval()
    except FileNotFoundError as e:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ ¸å¿ƒæ–‡ä»¶ - {e}");
        return

    # --- å‡†å¤‡â€œæ¯ä½“â€æµé‡ ---
    print("\næ­£åœ¨å‡†å¤‡è‰¯æ€§æµé‡ä½œä¸ºç”Ÿæˆæ¯ä½“...")
    df_benign_source = df_train_full[df_train_full['label'] == 0].copy().head(NUM_TO_GENERATE)
    if len(df_benign_source) < NUM_TO_GENERATE:
        print(f"è­¦å‘Š: è®­ç»ƒé›†ä¸­è‰¯æ€§æµé‡ä¸è¶³ {NUM_TO_GENERATE}, å°†ä½¿ç”¨ {len(df_benign_source)} æ¡ã€‚")
    if len(df_benign_source) < WINDOW_SIZE:
        print(f"é”™è¯¯: å¯ç”¨è‰¯æ€§æµé‡ä¸è¶³ {WINDOW_SIZE} æ¡!");
        return

    # âœ… 3. æŒ‰ä¸‰å±‚ä½“ç³»å‡†å¤‡æ•°æ®
    # å…ˆç”¨scalerè½¬æ¢æ‰€æœ‰é˜²å¾¡è€…èƒ½çœ‹åˆ°çš„ç‰¹å¾
    X_benign_def_scaled = scaler.transform(df_benign_source[DEFENDER_SET].values)
    df_benign_scaled = pd.DataFrame(X_benign_def_scaled, columns=DEFENDER_SET)

    # --- æ‰§è¡Œå¢é‡æ³¨å…¥æµç¨‹ ---
    print("\nå¼€å§‹æ‰§è¡Œ å¢é‡(Delta) æ³¨å…¥æµç¨‹...")
    # æ­¥éª¤1: ç¼–ç è‰¯æ€§æµé‡åˆ°æ½œåœ¨ç©ºé—´ (åªä½¿ç”¨æ”»å‡»è€…è®¤çŸ¥é›†)
    print("  - æ­¥éª¤1: å°†'æ”»å‡»è€…è®¤çŸ¥é›†'ç¼–ç ä¸ºæ½œåœ¨è¡¨ç¤º(z)...")
    with torch.no_grad():
        X_benign_knowledge_tensor = torch.tensor(df_benign_scaled[ATTACKER_KNOWLEDGE_SET].values,
                                                 dtype=torch.float32).to(device)
        benign_labels = torch.zeros(len(X_benign_knowledge_tensor), NUM_CLASSES_CAE, device=device);
        benign_labels[:, 0] = 1
        Z_benign_latent = cae_model.encode(X_benign_knowledge_tensor, benign_labels)

    # æ­¥éª¤2: ç”¨LSTMé¢„æµ‹â€œå¢é‡â€ (è¾“å‡ºç»´åº¦ä¸ºæ”»å‡»è€…è¡ŒåŠ¨é›†)
    print("  - æ­¥éª¤2: ç”¨LSTMé¢„æµ‹'æ”»å‡»è€…è¡ŒåŠ¨é›†'ä¸Šçš„ç‰¹å¾å¢é‡(Delta)...")
    latent_sequences = create_latent_sequences_for_generation(Z_benign_latent.cpu().numpy(), WINDOW_SIZE)
    latent_sequences_tensor = torch.FloatTensor(latent_sequences).to(device)
    condition_tensor = torch.zeros(len(latent_sequences_tensor), NUM_CLASSES_CAE, device=device);
    condition_tensor[:, 1] = 1
    with torch.no_grad():
        predicted_deltas = lstm_model(latent_sequences_tensor, condition_tensor).cpu().numpy()

    # âœ… 4. ç²¾ç¡®åº”ç”¨å¢é‡
    print(f"  - æ­¥éª¤3: æ­£åœ¨åº”ç”¨é¢„æµ‹çš„å¢é‡ (æ”¾å¤§ {PERTURBATION_STRENGTH_ALPHA} å€)...")
    num_generated = len(predicted_deltas)
    # æˆ‘ä»¬çš„â€œç”»å¸ƒâ€æ˜¯å®Œæ•´çš„é˜²å¾¡è€…è§†é‡
    adversarial_features_scaled = np.copy(X_benign_def_scaled)
    # æ‰¾åˆ°è¡ŒåŠ¨é›†åœ¨å¤§ç”»å¸ƒä¸Šçš„ç²¾ç¡®ä½ç½®
    action_indices_in_defender_set = [DEFENDER_SET.index(f) for f in ATTACKER_ACTION_SET]

    for i in tqdm(range(num_generated), desc="åº”ç”¨æ‰°åŠ¨"):
        target_sample_index = i + WINDOW_SIZE - 1
        if target_sample_index >= len(adversarial_features_scaled): break
        adversarial_features_scaled[target_sample_index, action_indices_in_defender_set] += (
                predicted_deltas[i] * PERTURBATION_STRENGTH_ALPHA)

    # --- åç»­å¤„ç† ---
    adversarial_features_scaled = np.clip(adversarial_features_scaled, 0, 1)
    # æˆ‘ä»¬åªä¿ç•™é‚£äº›è¢«æˆåŠŸæ‰°åŠ¨çš„æ ·æœ¬
    final_generated_features = adversarial_features_scaled[WINDOW_SIZE - 1: WINDOW_SIZE - 1 + num_generated]

    print("\næ­£åœ¨åå®šæ ‡å¹¶å°†æœ€ç»ˆä¼ªè£…æµé‡ä¿å­˜åˆ°CSV...")
    # åå®šæ ‡æ—¶ï¼Œ scaleræœŸæœ›å¾—åˆ°DEFENDER_SETç»´åº¦çš„è¾“å…¥
    final_features_original_scale = scaler.inverse_transform(final_generated_features)
    df_camouflage = pd.DataFrame(final_features_original_scale, columns=DEFENDER_SET)
    df_camouflage.to_csv(OUTPUT_CAMOUFLAGE_PATH, index=False)

    print(f"\nâœ… {len(df_camouflage)} æ¡ä¼ªè£…Botæµé‡ç”Ÿæˆå®Œæ¯•ï¼æ–‡ä»¶å·²ä¿å­˜åˆ°: {OUTPUT_CAMOUFLAGE_PATH}")


if __name__ == "__main__":
    main()