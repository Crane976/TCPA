# In a new file: models/train_cnn_hunter.py
import pandas as pd
import numpy as np
import os
import sys
import joblib
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
from sklearn.metrics import classification_report, f1_score
from sklearn.model_selection import train_test_split
from tqdm import tqdm

# ==========================================================
# --- Path Setup & Imports ---
# ==========================================================
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.append(project_root)

from config import DEFENDER_SET, set_seed
# âœ… 1. å¯¼å…¥æ–°çš„CNNæ¨¡å‹å’Œæˆ‘ä»¬ä¹‹å‰å®šä¹‰çš„FocalLoss
from models.cnn_architecture import CNN_Classifier
from models.mlp_architecture import FocalLoss

# ==========================================================
# --- 1. Configuration ---
# ==========================================================
TRAIN_SET_PATH = os.path.join(project_root, 'data', 'splits', 'training_set.csv')
TEST_SET_PATH = os.path.join(project_root, 'data', 'splits', 'holdout_test_set.csv')
SCALER_PATH = os.path.join(project_root, 'models', 'global_scaler.pkl')
# âœ… 2. ä¸ºæ–°æ¨¡å‹æŒ‡å®šæ–°çš„ä¿å­˜è·¯å¾„
CNN_HUNTER_MODEL_PATH = os.path.join(project_root, 'models', 'cnn_hunter.pt')

FEATURE_DIM = len(DEFENDER_SET)
EPOCHS = 100
BATCH_SIZE = 256
VALIDATION_SPLIT = 0.2
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
RANDOM_SEED = 2025
BEST_PARAMS = {'learning_rate': 0.0005}

# ==========================================================
# --- 2. Main Training Function ---
# ==========================================================
def main():
    set_seed(RANDOM_SEED)
    print("=" * 60)
    print("ğŸš€ å¼€å§‹è®­ç»ƒ 1D-CNN Hunter (Focal Loss + é˜ˆå€¼ä¼˜åŒ–)...")
    print("=" * 60)
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # --- æ•°æ®åŠ è½½å’Œå‡†å¤‡ (ä¸MLPç‰ˆæœ¬å®Œå…¨ç›¸åŒ) ---
    print("\n[æ­¥éª¤] æ­£åœ¨åŠ è½½æ•°æ®å’ŒScaler...")
    df_train_full = pd.read_csv(TRAIN_SET_PATH)
    df_test = pd.read_csv(TEST_SET_PATH)
    scaler = joblib.load(SCALER_PATH)
    feature_names = scaler.feature_names_in_
    X_test_scaled = scaler.transform(df_test[feature_names].values)
    y_test = df_test['label'].values
    X_train_full_scaled = scaler.transform(df_train_full[feature_names].values)
    y_train_full = df_train_full['label'].values
    X_train, X_val, y_train, y_val = train_test_split(
        X_train_full_scaled, y_train_full, test_size=VALIDATION_SPLIT, random_state=RANDOM_SEED, stratify=y_train_full
    )
    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32).unsqueeze(1))
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    val_tensor_x = torch.tensor(X_val, dtype=torch.float32).to(device)
    val_tensor_y = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1).to(device)
    print("âœ… æ•°æ®å‡†å¤‡å®Œæ¯•ã€‚")

    # --- æ¨¡å‹åˆå§‹åŒ–ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨ ---
    benign_ratio = (y_train_full == 0).sum() / len(y_train_full)
    # âœ… 3. åˆå§‹åŒ–CNNæ¨¡å‹
    model = CNN_Classifier(feature_dim=FEATURE_DIM).to(device)
    criterion = FocalLoss(alpha=benign_ratio, gamma=2.0)
    optimizer = torch.optim.AdamW(model.parameters(), lr=BEST_PARAMS['learning_rate'])
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=False)

    print("\n[æ­¥éª¤1] æ­£åœ¨è®­ç»ƒæ¨¡å‹...")
    best_val_loss = float('inf')
    for epoch in tqdm(range(EPOCHS), desc="Training"):
        model.train()
        for x_batch, y_batch in train_loader:
            x_batch, y_batch = x_batch.to(device), y_batch.to(device)
            # CNNçš„è®­ç»ƒè¿‡ç¨‹ä¸MLPå®Œå…¨ä¸€æ ·
            logits = model(x_batch)
            loss = criterion(logits, y_batch)
            optimizer.zero_grad(); loss.backward(); optimizer.step()
        model.eval()
        with torch.no_grad():
            val_logits = model(val_tensor_x)
            val_loss = criterion(val_logits, val_tensor_y).item()
        scheduler.step(val_loss)
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), CNN_HUNTER_MODEL_PATH)

    print(f"\nâœ… è®­ç»ƒå®Œæˆï¼Œæœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")

    # --- åœ¨éªŒè¯é›†ä¸Šå¯»æ‰¾æœ€ä½³å†³ç­–é˜ˆå€¼ ---
    print("\n[æ­¥éª¤2] æ­£åœ¨éªŒè¯é›†ä¸Šå¯»æ‰¾æœ€ä½³å†³ç­–é˜ˆå€¼...")
    final_model = CNN_Classifier(feature_dim=FEATURE_DIM).to(device)
    final_model.load_state_dict(torch.load(CNN_HUNTER_MODEL_PATH, map_location=device))
    final_model.eval()
    with torch.no_grad():
        val_probs = final_model.predict(val_tensor_x).cpu().numpy()
    best_threshold, best_f1 = 0.5, 0
    for threshold in np.arange(0.01, 1.0, 0.01):
        y_val_pred = (val_probs > threshold).astype(int)
        current_f1 = f1_score(y_val, y_val_pred, pos_label=1)
        if current_f1 > best_f1:
            best_f1, best_threshold = current_f1, threshold
    print(f"âœ… æœ€ä½³é˜ˆå€¼æŸ¥æ‰¾å®Œæ¯•: {best_threshold:.2f} (åœ¨è¯¥é˜ˆå€¼ä¸‹éªŒè¯é›†F1åˆ†æ•°ä¸º: {best_f1:.4f})")

    # --- ä½¿ç”¨æœ€ä½³é˜ˆå€¼åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæœ€ç»ˆè¯„ä¼° ---
    print("\n--- æœ€ç»ˆ'1D-CNN Hunter'åœ¨ã€ç•™å‡ºæµ‹è¯•é›†ã€‘ä¸Šçš„çœŸå®æ€§èƒ½æŠ¥å‘Š ---")
    with torch.no_grad():
        test_tensor_x = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)
        test_probs = final_model.predict(test_tensor_x).cpu().numpy()
        y_pred = (test_probs > best_threshold).astype(int)
    print(classification_report(y_test, y_pred, target_names=['Benign (0)', 'Bot (1)'], digits=4))

if __name__ == "__main__":
    main()