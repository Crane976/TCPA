# models/train_xgboost_hunter.py (Final Corrected Version)
import pandas as pd
import numpy as np
import os
import sys
import joblib
import xgboost as xgb
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# ==========================================================
# --- è·¯å¾„ä¿®æ­£ä¸æ¨¡å—å¯¼å…¥ ---
# ==========================================================
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.append(project_root)


# âœ… 1. å¯¼å…¥æ–°çš„ç‰¹å¾é›†
from config import DEFENDER_SET, set_seed


# ==========================================================
# --- ä¸­æ–‡æ˜¾ç¤ºé…ç½® ---
# ==========================================================
try:
    plt.rcParams['font.sans-serif'] = ['SimHei']
    plt.rcParams['axes.unicode_minus'] = False
    print("å·²è®¾ç½®å­—ä½“ä¸º SimHeiã€‚")
except Exception:
    print("è­¦å‘Š: æœªæ‰¾åˆ°SimHeiå­—ä½“ï¼Œä¸­æ–‡å¯èƒ½æ— æ³•æ˜¾ç¤ºã€‚")

# ==========================================================
# --- 1. é…ç½®åŒº ---
# ==========================================================
# âœ… æ ¸å¿ƒè¾“å…¥: ä½¿ç”¨ä¸¥æ ¼åˆ†ç¦»çš„æ•°æ®é›†
TRAIN_SET_PATH = os.path.join(project_root, 'data', 'splits', 'training_set.csv')
TEST_SET_PATH = os.path.join(project_root, 'data', 'splits', 'holdout_test_set.csv')
SCALER_PATH = os.path.join(project_root, 'models', 'global_scaler.pkl')

# --- è¾“å‡º ---
MODELS_DIR = os.path.join(project_root, 'models')
FIGURES_DIR = os.path.join(project_root, 'figures')
HUNTER_MODEL_PATH = os.path.join(MODELS_DIR, 'xgboost_hunter.pkl')


# ==========================================================
# --- 2. ä¸»è®­ç»ƒå‡½æ•° ---
# ==========================================================
def main():
    set_seed(2025)  # âœ… åœ¨mainå‡½æ•°å¼€å¤´è°ƒç”¨
    print("==========================================================")
    print("ğŸš€ å¼€å§‹è®­ç»ƒ'å‡è¡¡å‹çŒæ‰‹' (åœ¨ä¸¥æ ¼åˆ†ç¦»çš„æ•°æ®é›†ä¸Š)...")
    print("==========================================================")

    # --- 1. åŠ è½½æ‰€æœ‰èµ„äº§ ---
    print("æ­£åœ¨åŠ è½½è®­ç»ƒé›†ã€ç•™å‡ºæµ‹è¯•é›†å’Œå…¨å±€Scaler...")
    try:
        df_train = pd.read_csv(TRAIN_SET_PATH)
        df_test = pd.read_csv(TEST_SET_PATH)
        scaler = joblib.load(SCALER_PATH)
    except FileNotFoundError as e:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ ¸å¿ƒæ–‡ä»¶ - {e}");
        return

    # --- 2. å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾ ---
    # ä»DataFrameä¸­åˆ†ç¦»ç‰¹å¾ (X) å’Œæ ‡ç­¾ (y)
    X_train_raw = df_train[DEFENDER_SET]
    y_train = df_train['label']
    X_test_raw = df_test[DEFENDER_SET]
    y_test = df_test['label']

    # âœ… æ ¸å¿ƒæ“ä½œ: ä½¿ç”¨åŠ è½½çš„Scaleråˆ†åˆ«è½¬æ¢è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
    print("æ­£åœ¨ä½¿ç”¨Scalerè½¬æ¢æ•°æ®...")
    X_train_scaled = scaler.transform(X_train_raw)
    X_test_scaled = scaler.transform(X_test_raw)

    print(f"è®­ç»ƒé›†å¤§å°: {X_train_scaled.shape}, æµ‹è¯•é›†å¤§å°: {X_test_scaled.shape}")

    # --- 3. ä½¿ç”¨GridSearchCVå¯»æ‰¾æœ€ä½³è¶…å‚æ•° ---
    print("\n[æ­¥éª¤1] æ­£åœ¨é€šè¿‡GridSearchCVå¯»æ‰¾æœ€ä½³è¶…å‚æ•°...")
    hunter_model_base = xgb.XGBClassifier(
        objective='binary:logistic', eval_metric='logloss', use_label_encoder=False,
        n_estimators=100, n_jobs=-1, random_state=2025
    )
    param_grid = {
        'scale_pos_weight': [5, 10, 15, 20],
        'max_depth': [5, 6, 7],
        'learning_rate': [0.05, 0.1]
    }
    grid_search = GridSearchCV(estimator=hunter_model_base, param_grid=param_grid, scoring='f1', cv=3, verbose=2)

    # âœ… åœ¨æ­£ç¡®çš„ã€å½’ä¸€åŒ–åçš„è®­ç»ƒæ•°æ®ä¸Šæ‰§è¡Œæœç´¢
    grid_search.fit(X_train_scaled, y_train)

    print(f"\næœç´¢å®Œæˆï¼ -> æœ€ä½³å‚æ•°ç»„åˆ: {grid_search.best_params_}")

    # --- 4. ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒæœ€ç»ˆæ¨¡å‹ ---
    print("\n[æ­¥éª¤2] æ­£åœ¨ä½¿ç”¨æ‰¾åˆ°çš„æœ€ä½³å‚æ•°è®­ç»ƒæœ€ç»ˆçš„'çŒæ‰‹'æ¨¡å‹...")
    best_params = grid_search.best_params_
    hunter_model = xgb.XGBClassifier(
        objective='binary:logistic', eval_metric='logloss', use_label_encoder=False,
        n_estimators=200, n_jobs=-1, random_state=42, **best_params
    )
    hunter_model.fit(X_train_scaled, y_train)
    joblib.dump(hunter_model, HUNTER_MODEL_PATH)
    print(f"âœ… æœ€ç»ˆ'çŒæ‰‹'æ¨¡å‹å·²ä¿å­˜åˆ°: {HUNTER_MODEL_PATH}")

    # --- 5. åœ¨ä»æœªè§è¿‡çš„ç•™å‡ºæµ‹è¯•é›†ä¸Šè¿›è¡Œæœ€ç»ˆè¯„ä¼° ---
    print("\n--- 'çŒæ‰‹'åœ¨ã€ç•™å‡ºæµ‹è¯•é›†ã€‘ä¸Šçš„çœŸå®æ€§èƒ½æŠ¥å‘Š ---")
    y_pred = hunter_model.predict(X_test_scaled)
    print(classification_report(y_test, y_pred, target_names=['Benign (0)', 'Bot (1)'], digits=4))

    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Benign', 'Bot'], yticklabels=['Benign', 'Bot'])
    plt.title("'çŒæ‰‹'æ¨¡å‹åœ¨ç•™å‡ºæµ‹è¯•é›†ä¸Šçš„æ··æ·†çŸ©é˜µ")
    plt.xlabel('é¢„æµ‹æ ‡ç­¾');
    plt.ylabel('çœŸå®æ ‡ç­¾')
    plt.tight_layout()
    cm_path = os.path.join(FIGURES_DIR, "hunter_holdout_test_confusion_matrix.png")
    plt.savefig(cm_path, dpi=300)
    print(f"âœ… æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ°: {cm_path}")
    plt.show()


if __name__ == "__main__":
    main()