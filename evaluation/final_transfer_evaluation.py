# evaluation/final_transfer_evaluation.py (FINAL: LABEL NORMALIZATION FIX)
import pandas as pd
import numpy as np
import os
import sys
import joblib
import torch
import torch.nn as nn
import xgboost as xgb
from sklearn.neighbors import KNeighborsClassifier

project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path: sys.path.append(project_root)

# ğŸ”¥ å¼•å…¥ config æ¨¡å—
import config
from config import DEFENDER_SET, set_seed
from models.mlp_architecture import MLP_Classifier
from models.cnn_architecture import CNN_Classifier

# ==============================================================================
# ğŸ¯ æœ€ä½³é˜ˆå€¼é…ç½®
# ==============================================================================
# é’ˆå¯¹ IDS2017 çš„å¾®è°ƒé˜ˆå€¼
MODEL_THRESHOLDS_2017 = {
    "KNN Hunter": 0.90,
    "1D-CNN Hunter": 0.90,
    "XGBoost Hunter": 0.85,
    "MLP Hunter": 0.76
}

# é’ˆå¯¹ IDS2018 çš„å¾®è°ƒé˜ˆå€¼
MODEL_THRESHOLDS_2018 = {
    "KNN Hunter": 0.30,
    "1D-CNN Hunter": 0.57,
    "XGBoost Hunter": 0.60,
    "MLP Hunter": 0.57
}

# åŠ¨æ€é€‰æ‹©
MODEL_THRESHOLDS = MODEL_THRESHOLDS_2018 if config.CURRENT_DATASET == 'CSE-CIC-IDS2018' else MODEL_THRESHOLDS_2017


# ------------------------------------------------------------------------------
# 2. æ ¸å¿ƒè¯„ä¼°å‡½æ•° (ä¿æŒä¸å˜)
# ------------------------------------------------------------------------------
def evaluate_hunter(hunter_name, hunter_model, X_cam_scaled, X_benign_test, X_bot_test, y_bot_test, device,
                    threshold=0.5):
    print("\n" + "=" * 50)
    print(f"--- æ­£åœ¨è¯„ä¼°å¯¹æŠ—: {hunter_name} ---")
    print(f"    ğŸ‘‰ ä½¿ç”¨æœ€ä½³å†³ç­–é˜ˆå€¼: {threshold:.2f}")

    # --- ç»Ÿä¸€é¢„æµ‹æ¥å£ ---
    if isinstance(hunter_model, nn.Module):
        hunter_model.eval()
        with torch.no_grad():
            t_cam = torch.tensor(X_cam_scaled, dtype=torch.float32).to(device)
            t_benign = torch.tensor(X_benign_test, dtype=torch.float32).to(device)
            t_bot = torch.tensor(X_bot_test, dtype=torch.float32).to(device)

            preds_cam = (hunter_model.predict(t_cam) > threshold).int().cpu().numpy().flatten()
            preds_benign = (hunter_model.predict(t_benign) > threshold).int().cpu().numpy().flatten()
            preds_bot = (hunter_model.predict(t_bot) > threshold).int().cpu().numpy().flatten()

    else:
        def batch_predict_with_threshold(model, data, thr, batch_size=5000):
            n_samples = len(data)
            preds = []
            for i in range(0, n_samples, batch_size):
                batch = data[i:i + batch_size]
                probs = model.predict_proba(batch)[:, 1]
                batch_preds = (probs >= thr).astype(int)
                preds.extend(batch_preds)
            return np.array(preds)

        preds_cam = batch_predict_with_threshold(hunter_model, X_cam_scaled, threshold)
        preds_benign = batch_predict_with_threshold(hunter_model, X_benign_test, threshold)
        preds_bot = batch_predict_with_threshold(hunter_model, X_bot_test, threshold)

    # --- è®¡ç®—æŒ‡æ ‡ ---
    decoy_success_count = np.sum(preds_cam == 1)
    decoy_rate = decoy_success_count / len(X_cam_scaled) * 100

    base_tp = np.sum(preds_bot == 1)
    base_fn = len(y_bot_test) - base_tp
    recall = base_tp / (base_tp + base_fn) * 100

    base_fp = np.sum(preds_benign == 1)

    base_alerts = base_fp + base_tp
    mix_alerts = base_alerts + decoy_success_count

    dsr = (decoy_success_count / mix_alerts) * 100 if mix_alerts > 0 else 0
    base_precision = (base_tp / base_alerts) * 100 if base_alerts > 0 else 0
    hunter_precision_decayed = (base_tp / mix_alerts) * 100 if mix_alerts > 0 else 0

    print(f"  - è¯±é¥µç”ŸæˆæˆåŠŸæ•° (Decoy Success): {decoy_success_count} / {len(X_cam_scaled)} ({decoy_rate:.2f}%)")
    print(f"  - çœŸå®Botæ•è·ç‡ (Recall): {recall:.2f}%")
    print(f"  - åŸå§‹è¯¯æŠ¥æ•° (Benign FP): {base_fp}")
    print("---------------------------------------------")
    print(f"  ğŸ¯ è­¦æŠ¥æ±¡æŸ“ç‡ (DSR): {dsr:.2f}%")
    print(f"  ğŸ“‰ ç²¾ç¡®ç‡ä» {base_precision:.2f}% è¡°å‡ä¸º: {hunter_precision_decayed:.2f}%")

    return {
        "Hunter": hunter_name,
        "Threshold": threshold,
        "Decoy Rate (%)": decoy_rate,
        "Recall (%)": recall,
        "Base Precision (%)": base_precision,
        "Decayed Precision (%)": hunter_precision_decayed,
        "DSR (Pollution) (%)": dsr
    }


# ------------------------------------------------------------------------------
# 3. ä¸»æµç¨‹
# ------------------------------------------------------------------------------
def main():
    set_seed(2025)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    print("=" * 60)
    print(f"ğŸš€ æœ€ç»ˆè¿ç§»æ”»å‡»è¯„ä¼° ({config.CURRENT_DATASET})")
    print("=" * 60)

    # 1. åŠ¨æ€è·¯å¾„é…ç½®
    decoy_filename = f'baseline_ProGen_CIC-IDS2017.csv'
    CAMOUFLAGE_BOT_PATH = os.path.join(project_root, 'data', 'generated', decoy_filename)
    TEST_SET_PATH = os.path.join(project_root, 'data', 'splits', 'holdout_test_set.csv')
    SCALER_PATH = os.path.join(project_root, 'models', 'global_scaler.pkl')

    MODEL_PATHS = {
        "1D-CNN Hunter": os.path.join(project_root, 'models', 'cnn_hunter.pt'),
        "XGBoost Hunter": os.path.join(project_root, 'models', 'xgboost_hunter.pkl'),
        "KNN Hunter": os.path.join(project_root, 'models', 'knn_hunter.pkl'),
        "MLP Hunter": os.path.join(project_root, 'models', 'mlp_hunter.pt'),
    }

    # 2. åŠ è½½æ•°æ®
    print(f"\n[æ­¥éª¤1] æ­£åœ¨åŠ è½½æ•°æ®...\n  -> è¯±é¥µ: {CAMOUFLAGE_BOT_PATH}\n  -> æµ‹è¯•é›†: {TEST_SET_PATH}")
    try:
        df_cam = pd.read_csv(CAMOUFLAGE_BOT_PATH)
        df_test = pd.read_csv(TEST_SET_PATH)
        scaler = joblib.load(SCALER_PATH)
    except FileNotFoundError as e:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ - {e}")
        return

    # 3. æ•°æ®é¢„å¤„ç†
    df_cam.replace([np.inf, -np.inf], np.nan, inplace=True)
    df_cam.dropna(subset=DEFENDER_SET, inplace=True)
    df_test.replace([np.inf, -np.inf], np.nan, inplace=True)
    df_test.dropna(subset=DEFENDER_SET, inplace=True)

    # å…¼å®¹ Label åˆ—å
    label_col = 'Label' if 'Label' in df_test.columns else 'label'

    # ğŸ”¥ğŸ”¥ğŸ”¥ æ ¸å¿ƒä¿®å¤: æ ‡ç­¾æ ‡å‡†åŒ– (String -> Int) ğŸ”¥ğŸ”¥ğŸ”¥
    # å¦‚æœæ£€æµ‹åˆ°æ ‡ç­¾æ˜¯å­—ç¬¦ä¸²(Object)ï¼Œå¼ºåˆ¶è½¬æ¢ä¸º 0/1
    if df_test[label_col].dtype == object:
        print(f"   -> âš ï¸ æ£€æµ‹åˆ°å­—ç¬¦ä¸²æ ‡ç­¾ {df_test[label_col].unique()}ï¼Œæ­£åœ¨æ ‡å‡†åŒ–ä¸º [0, 1]...")
        # é€»è¾‘ï¼š'Benign' (å¿½ç•¥å¤§å°å†™) -> 0, å…¶ä»– -> 1
        df_test[label_col] = df_test[label_col].apply(lambda x: 0 if str(x).lower() == 'benign' else 1)
        print(f"   -> æ ‡ç­¾æ ‡å‡†åŒ–å®Œæˆã€‚Benign(0): {len(df_test[df_test[label_col]==0])}, Bot(1): {len(df_test[df_test[label_col]==1])}")

    # ğŸ”¥ IDS2018 æˆ˜æœ¯çª—å£é‡‡æ ·é€»è¾‘
    if config.CURRENT_DATASET == 'CSE-CIC-IDS2018':
        print("\nâš ï¸ æ£€æµ‹åˆ°å¤§è§„æ¨¡æ•°æ®é›† (IDS2018)ï¼Œæ‰§è¡Œè¯„ä¼°é˜¶æ®µçš„æˆ˜æœ¯é‡‡æ ·...")

        # æ­¤æ—¶ df_test[label_col] å·²ç»æ˜¯ 0/1 äº†ï¼Œå¯ä»¥å®‰å…¨ç­›é€‰
        df_bot_full = df_test[df_test[label_col] == 1]
        if len(df_bot_full) > 1000:
            df_bot_sample = df_bot_full.sample(n=1000, random_state=2025)
        else:
            df_bot_sample = df_bot_full

        # é‡‡æ ·èƒŒæ™¯æµé‡
        df_benign_full = df_test[df_test[label_col] == 0]
        # è¿™é‡Œçš„ 100000 å¯¹åº”ç”Ÿæˆé˜¶æ®µçš„è¯±é¥µæ•°é‡ï¼Œä¿æŒ 1:1 æ³¨å…¥æ¯”æˆ– 100:1 å‹åˆ¶æ¯”
        sample_size = min(len(df_benign_full), 100000)
        df_benign_sample = df_benign_full.sample(n=sample_size, random_state=2025)

        df_test_eval = pd.concat([df_bot_sample, df_benign_sample])
        print(f"   -> é‡‡æ ·åæµ‹è¯•é›†: {len(df_bot_sample)} Bot + {len(df_benign_sample)} Benign")
    else:
        # IDS2017 å…¨é‡è¯„ä¼°
        df_test_eval = df_test
        print(f"   -> å…¨é‡æµ‹è¯•é›†: {len(df_test_eval)} æ ·æœ¬")

    print(f"ä½¿ç”¨ {len(DEFENDER_SET)} ç»´ç‰¹å¾è¿›è¡Œè¯„ä¼°...")

    # 4. ç‰¹å¾ç¼©æ”¾
    X_cam_scaled = scaler.transform(df_cam[DEFENDER_SET])

    X_benign_scaled = scaler.transform(df_test_eval[df_test_eval[label_col] == 0][DEFENDER_SET])
    X_bot_scaled = scaler.transform(df_test_eval[df_test_eval[label_col] == 1][DEFENDER_SET])
    y_bot_numpy = df_test_eval[df_test_eval[label_col] == 1][label_col].values

    # 5. åŠ è½½æ¨¡å‹å¹¶è¯„ä¼°
    print("\n[æ­¥éª¤2] å¼€å§‹è¯„ä¼°...")
    results_list = []

    for name, path in MODEL_PATHS.items():
        if not os.path.exists(path):
            print(f"âš ï¸ è·³è¿‡ {name}: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ ({path})")
            continue

        try:
            threshold = MODEL_THRESHOLDS.get(name, 0.5)

            if name == "MLP Hunter":
                model = MLP_Classifier(feature_dim=len(DEFENDER_SET)).to(device)
                model.load_state_dict(torch.load(path, map_location=device))
                result = evaluate_hunter(name, model, X_cam_scaled, X_benign_scaled, X_bot_scaled, y_bot_numpy, device,
                                         threshold)

            elif name == "1D-CNN Hunter":
                model = CNN_Classifier(feature_dim=len(DEFENDER_SET)).to(device)
                model.load_state_dict(torch.load(path, map_location=device))
                result = evaluate_hunter(name, model, X_cam_scaled, X_benign_scaled, X_bot_scaled, y_bot_numpy, device,
                                         threshold)

            else:
                # Sklearn/XGB
                model = joblib.load(path)
                result = evaluate_hunter(name, model, X_cam_scaled, X_benign_scaled, X_bot_scaled, y_bot_numpy, device,
                                         threshold)

            results_list.append(result)
        except Exception as e:
            print(f"âš ï¸ æ— æ³•åŠ è½½æˆ–è¯„ä¼° {name}: {e}")

    # 6. æ±‡æ€»æŠ¥å‘Š
    print("\n\n" + "=" * 100)
    print(f"--- æœ€ç»ˆè¯„ä¼°æ±‡æ€»æŠ¥å‘Š ({config.CURRENT_DATASET}) ---")
    print("=" * 100)
    if results_list:
        results_df = pd.DataFrame(results_list).set_index("Hunter")
        print(results_df.to_string(float_format="%.2f"))

        save_path = os.path.join(project_root, 'data', f'evaluation_results_{config.CURRENT_DATASET}.csv')
        results_df.to_csv(save_path)
        print(f"\nâœ… ç»“æœå·²ä¿å­˜è‡³: {save_path}")
    else:
        print("æ— ç»“æœã€‚")


if __name__ == "__main__":
    main()