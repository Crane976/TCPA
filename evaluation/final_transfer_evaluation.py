# evaluation/final_transfer_evaluation.py (FINAL GRAND REVIEW VERSION)
import pandas as pd
import numpy as np
import os
import sys
import joblib
import torch
import torch.nn as nn
from sklearn.metrics import f1_score  # ç”¨äºå¯»æ‰¾é˜ˆå€¼
import xgboost as xgb
from sklearn.model_selection import train_test_split

# ==========================================================
# --- Path Setup & Imports ---
# ==========================================================
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path: sys.path.append(project_root)

from config import DEFENDER_SET, set_seed
# âœ… 1. å¯¼å…¥æ‰€æœ‰äº”ä¸ªæ¨¡å‹çš„æ¶æ„
from models.mlp_architecture import MLP_Classifier
from models.cnn_architecture import CNN_Classifier
from models.lstm_architecture import LSTM_Classifier
from models.transformer_architecture import Transformer_Classifier


# ==========================================================
# --- 1. Helper Function to Find Best Threshold ---
# ==========================================================
def find_best_threshold(model, X_val, y_val, device):
    """åœ¨éªŒè¯é›†ä¸Šä¸ºPyTorchæ¨¡å‹å¯»æ‰¾æœ€ä½³å†³ç­–é˜ˆå€¼"""
    model.eval()
    with torch.no_grad():
        val_probs = model.predict(torch.tensor(X_val, dtype=torch.float32).to(device)).cpu().numpy()

    best_threshold, best_f1 = 0.5, 0
    for threshold in np.arange(0.01, 1.0, 0.01):
        y_pred = (val_probs > threshold).astype(int)
        current_f1 = f1_score(y_val, y_pred, pos_label=1)
        if current_f1 > best_f1:
            best_f1, best_threshold = current_f1, threshold
    return best_threshold


# ==========================================================
# --- 2. Upgraded Evaluation Function ---
# ==========================================================
def evaluate_hunter(hunter_name, hunter_model, X_camouflage_scaled, X_benign_test, X_real_bot_test, y_real_bot_test,
                    device, threshold=0.5, batch_size=1024):  # âœ… å¢åŠ  batch_size å‚æ•°
    """
    è¯„ä¼°å•ä¸ªçŒæ‰‹æ¨¡å‹ï¼ˆå·²æ›´æ–°ä¸ºæ”¯æŒåˆ†æ‰¹æ¬¡é¢„æµ‹ï¼‰ã€‚
    - threshold: ä¸“ä¸ºPyTorchæ¨¡å‹è®¾è®¡çš„å†³ç­–é˜ˆå€¼
    - batch_size: é¢„æµ‹æ—¶ä½¿ç”¨çš„æ‰¹æ¬¡å¤§å°ï¼Œé˜²æ­¢CUDAé”™è¯¯
    """
    print("\n" + "=" * 50);
    print(f"--- æ­£åœ¨è¯„ä¼°å¯¹æŠ—: {hunter_name} ---");
    if not isinstance(hunter_model, xgb.XGBClassifier):
        print(f"    (ä½¿ç”¨æœ€ä½³é˜ˆå€¼: {threshold:.2f})")
    print("=" * 50)

    # æ ¹æ®æ¨¡å‹ç±»å‹è¿›è¡Œé¢„æµ‹
    if isinstance(hunter_model, nn.Module):
        hunter_model.eval()
        all_preds = []

        # --- âœ… åˆ†æ‰¹æ¬¡é¢„æµ‹ ---
        def batch_predict(X_data):
            preds = []
            data_tensor = torch.tensor(X_data, dtype=torch.float32)
            dataset = torch.utils.data.TensorDataset(data_tensor)
            loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)
            with torch.no_grad():
                for batch in loader:
                    batch_data = batch[0].to(device)
                    # ç¡®ä¿æ¨¡å‹æœ‰ predict æ–¹æ³•ï¼Œæˆ–è€…ç›´æ¥è°ƒç”¨ forward
                    if hasattr(hunter_model, 'predict'):
                        probs = hunter_model.predict(batch_data)
                    else:
                        probs = hunter_model(batch_data)

                    pred_labels = (probs > threshold).int().cpu().numpy().flatten()
                    preds.extend(pred_labels)
            return np.array(preds)

        preds_cam = batch_predict(X_camouflage_scaled)
        preds_benign = batch_predict(X_benign_test)
        preds_bot = batch_predict(X_real_bot_test)

    else:  # é€‚ç”¨äºXGBoost
        preds_cam = hunter_model.predict(X_camouflage_scaled)
        preds_benign = hunter_model.predict(X_benign_test)
        preds_bot = hunter_model.predict(X_real_bot_test)

    # è®¡ç®—å„é¡¹æŒ‡æ ‡ (è¿™éƒ¨åˆ†é€»è¾‘ä¸å˜)
    deceived_count = np.sum(preds_cam)
    deception_rate = deceived_count / len(X_camouflage_scaled) * 100

    base_fp = np.sum(preds_benign)
    base_tp = np.sum(preds_bot)
    base_fn = len(y_real_bot_test) - base_tp

    recall = base_tp / (base_tp + base_fn) * 100 if (base_tp + base_fn) > 0 else 0

    base_alerts = base_fp + base_tp
    mix_alerts = base_alerts + deceived_count

    dsr = (deceived_count / mix_alerts) * 100 if mix_alerts > 0 else 0
    base_precision = (base_tp / base_alerts) * 100 if base_alerts > 0 else 0
    hunter_precision_decayed = (base_tp / mix_alerts) * 100 if mix_alerts > 0 else 0

    print(f"  - æˆåŠŸæ¬ºéª—çš„ä¼ªè£…Botæ•°é‡: {deceived_count} / {len(X_camouflage_scaled)} ({deception_rate:.2f}%)")
    print(f"  - çœŸå®Botæ•è·ç‡ (Recall): {recall:.2f}%")
    print(f"  - è¯¯æŠ¥æ•° (Benign -> Bot): {base_fp}")
    print("---------------------------------------------")
    print(f"  ğŸ¯ æœ€ç»ˆæ¬ºéª—æˆåŠŸç‡ (DSR): {dsr:.2f}%")
    print(f"  ğŸ“‰ ç²¾ç¡®ç‡ä» {base_precision:.2f}% è¡°å‡ä¸º: {hunter_precision_decayed:.2f}%")

    return {
        "Hunter": hunter_name,
        "Deception Rate (%)": deception_rate,
        "Recall (%)": recall,
        "Base Precision (%)": base_precision,
        "Decayed Precision (%)": hunter_precision_decayed,
        "DSR (%)": dsr
    }


# ==========================================================
# --- 3. Main Evaluation Orchestrator ---
# ==========================================================
def main():
    set_seed(2025)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # --- ç»Ÿä¸€çš„è·¯å¾„é…ç½® ---
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    CAMOUFLAGE_BOT_PATH = os.path.join(project_root, 'data', 'generated',
                                       'final_camouflage_bot_3tier_lstm.csv')
    TRAIN_SET_PATH = os.path.join(project_root, 'data', 'splits', 'training_set.csv')
    TEST_SET_PATH = os.path.join(project_root, 'data', 'splits', 'holdout_test_set.csv')
    SCALER_PATH = os.path.join(project_root, 'models', 'global_scaler.pkl')

    MODEL_PATHS = {
        "XGBoost Hunter": os.path.join(project_root, 'models', 'xgboost_hunter.pkl'),
        "MLP Hunter": os.path.join(project_root, 'models', 'mlp_hunter.pt'),
        "1D-CNN Hunter": os.path.join(project_root, 'models', 'cnn_hunter.pt'),
        "LSTM Hunter": os.path.join(project_root, 'models', 'lstm_hunter.pt'),
        "Transformer Hunter": os.path.join(project_root, 'models', 'transformer_hunter.pt'),
    }

    print("=" * 50);
    print("ğŸš€ æœ€ç»ˆè¿ç§»æ”»å‡»è¯„ä¼° (å¤§é˜…å…µ)...");
    print("=" * 50)

    # --- 1. åŠ è½½æ•°æ® ---
    print("\n[æ­¥éª¤1] æ­£åœ¨åŠ è½½æ¬ºéª—æµé‡ã€æµ‹è¯•é›†å’ŒScaler...")
    try:
        df_cam = pd.read_csv(CAMOUFLAGE_BOT_PATH)
        df_train = pd.read_csv(TRAIN_SET_PATH)  # éœ€è¦è®­ç»ƒé›†æ¥åˆ’åˆ†å‡ºéªŒè¯é›†
        df_test = pd.read_csv(TEST_SET_PATH)
        scaler = joblib.load(SCALER_PATH)
    except FileNotFoundError as e:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ ¸å¿ƒè¯„ä¼°æ–‡ä»¶ - {e}");
        return

    feature_names = scaler.feature_names_in_
    X_cam_scaled = scaler.transform(df_cam[feature_names].values)

    # å‡†å¤‡æµ‹è¯•æ•°æ®
    df_benign_test = df_test[df_test['label'] == 0]
    df_bot_test = df_test[df_test['label'] == 1]
    X_benign_scaled = scaler.transform(df_benign_test[feature_names].values)
    X_bot_scaled = scaler.transform(df_bot_test[feature_names].values)
    y_bot_numpy = df_bot_test['label'].values

    # å‡†å¤‡éªŒè¯æ•°æ® (ç”¨äºå¯»æ‰¾é˜ˆå€¼)
    X_train_scaled = scaler.transform(df_train[feature_names].values)
    y_train = df_train['label'].values
    _, X_val, _, y_val = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=2025, stratify=y_train)
    print("âœ… æ•°æ®åŠ è½½å’Œå‡†å¤‡å®Œæ¯•ã€‚")

    # --- 2. åŠ è½½æ‰€æœ‰æ¨¡å‹ ---
    print("\n[æ­¥éª¤2] æ­£åœ¨åŠ è½½æ‰€æœ‰çŒæ‰‹æ¨¡å‹...")
    hunters = {}
    try:
        # åŠ è½½XGBoost
        import xgboost as xgb
        hunters["XGBoost Hunter"] = joblib.load(MODEL_PATHS["XGBoost Hunter"])

        # åŠ è½½PyTorchæ¨¡å‹
        model_defs = {
            "MLP Hunter": MLP_Classifier,
            "1D-CNN Hunter": CNN_Classifier,
            "LSTM Hunter": LSTM_Classifier,
            "Transformer Hunter": Transformer_Classifier
        }
        for name, model_class in model_defs.items():
            model = model_class(feature_dim=len(DEFENDER_SET)).to(device)
            model.load_state_dict(torch.load(MODEL_PATHS[name], map_location=device))
            model.eval()
            hunters[name] = model
        print("âœ… æ‰€æœ‰æ¨¡å‹åŠ è½½å®Œæ¯•ã€‚")
    except (FileNotFoundError, KeyError) as e:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶æˆ–è·¯å¾„é…ç½®é”™è¯¯ - {e}");
        return

    # --- 3. è¯„ä¼°æ¯ä¸ªçŒæ‰‹å¹¶æ”¶é›†ç»“æœ ---
    print("\n[æ­¥éª¤3] å¼€å§‹é€ä¸€è¯„ä¼°çŒæ‰‹...")
    results_list = []
    for name, model in hunters.items():
        threshold = 0.5
        if isinstance(model, nn.Module):
            # ä¸ºæ¯ä¸ªNNæ¨¡å‹åŠ¨æ€å¯»æ‰¾æœ€ä½³é˜ˆå€¼
            threshold = find_best_threshold(model, X_val, y_val, device)

        result = evaluate_hunter(name, model, X_cam_scaled, X_benign_scaled, X_bot_scaled, y_bot_numpy, device,
                                 threshold)
        results_list.append(result)

    # --- 4. æ±‡æ€»å¹¶å±•ç¤ºæœ€ç»ˆç»“æœ ---
    print("\n\n" + "=" * 70)
    print("--- æœ€ç»ˆè¿ç§»æ”»å‡»è¯„ä¼°æ±‡æ€»æŠ¥å‘Š ---")
    print("=" * 70)

    results_df = pd.DataFrame(results_list)
    results_df = results_df.set_index("Hunter")
    print(results_df.to_string(float_format="%.2f"))

    print("\n" + "=" * 70);
    print("--- è¯„ä¼°å®Œæˆ ---");
    print("=" * 70)


if __name__ == "__main__":
    main()